{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JamesMTucker/DATA_340_NLP/blob/master/assignment_notebooks/Webscraping.ipynb)\n",
    "\n",
    "# Webscraping Assignment\n",
    "\n",
    "Reminder: you are permitted to work with another classmate on this assignment. If you do, please submit a single notebook with both of your names at the top.\n",
    "\n",
    "## Due date\n",
    "\n",
    "Friday, February 24 (12:00 pm), 2023\n",
    "\n",
    "## Assignment description\n",
    "\n",
    "In this project you will write a Jupyter Notebook or R Markdown file to scrape a selected website. You will need to:\n",
    "\n",
    "1. Write a function that takes a URL as input and returns the HTML of the page as a string.\n",
    "2. Inspect the HTML of the page and use regular expressions to extract the documents within the page.\n",
    "3. Model the documents in a corpus\n",
    "4. Analyze the corpus using the bag of words model\n",
    "5. Implement a TF-IDF model to extract the most n-important words for each document in the corpus.\n",
    "\n",
    "### Objective\n",
    "\n",
    "This assignment reinforces previous lecture topics on the linguistic background, properties of language, information theory, and Regular Expressions.\n",
    "\n",
    "\n",
    "## Submission medium\n",
    "\n",
    "Jupyter Notebook or R Markdown file. See additional instructions at the final section of this document.\n",
    "\n",
    "## Code Dependencies\n",
    "\n",
    "You will need to install the following packages:\n",
    "\n",
    "- `requests`\n",
    "- `re`\n",
    "- `beautifulsoup4`\n",
    "- `nltk`\n",
    "- `pandas`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "\n",
    "\n",
    "## Grading\n",
    "\n",
    "This assignment is worth 10 points. (extra credit 1 point to final grade if you create a heatmap of the TF-IDF matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark J Serena - mjserena@wm.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mjserena/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# For Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# For Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#import CountVectorizer if we just want a Bag of Words Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#import TfidfVectorizer if we want TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that takes a URL as input and returns the HTML of the page as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Write a function that takes a URL as input and returns the HTML of the page as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_html(url) -> str:\n",
    "    \"\"\"Get the HTML of a webpage and return the HTML as a string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL of the webpage to scrape.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The HTML of the webpage as a string.\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    html_source: str = requests.get(url).text\n",
    "    assert isinstance(html_source, str), \"The HTML should be a string.\"\n",
    "    return html_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inspect the HTML of the page. Can you identify any patterns in the HTML that might be useful for extracting the documents within the page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html source returned is type <class 'str'>\n",
      "but no html found, hmmm. may be time to brew a beautiful soup.\n"
     ]
    }
   ],
   "source": [
    "# Extract the the HTML source code from the URL (this is the same URL we used in class)\n",
    "url = \"https://www.gutenberg.org/files/1/1-0.txt\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('url request failed, best of luck')\n",
    "html_source = response.text\n",
    "print('html source returned is type',type(html_source))\n",
    "\n",
    "any_html = re.findall(r\"<html>\", html_source)\n",
    "if any_html == []:\n",
    "    print('but no html found, hmmm. may be time to brew a beautiful soup.')\n",
    "else:\n",
    "    print(any_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use the BeautifulSoup library to create a BeautifulSoup object from the HTML string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we found html! ['<html>', '<body>', '<p>', '<hart>', '</hart>', '</p>', '</body>', '</html>']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "\n",
    "soup = BeautifulSoup(html_source, \"lxml\")\n",
    "# lets look at our soup\n",
    "soup_html_source = soup.prettify()\n",
    "#lets check soup for html\n",
    "any_html = re.findall(r\"<.*>\", soup_html_source)\n",
    "if any_html == []:\n",
    "    print('but no html found, hmmm. may be time to brew a beautiful soup.')\n",
    "else:\n",
    "    print('we found html!',any_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract the HTML body text and examine the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please explain what the following line of code does in the cell below.\n",
    "body = soup.find(\"body\")\n",
    "\n",
    "# The above .find() function of soup will as named find any tags in the html source and their contents. \n",
    "# This particular example is looking for the body tag and its contents.\n",
    "# specifically anything between <body> and </body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above .find() function of soup will find any tags in the html source and their contents. This particular example is looking for the body tag and its contents. Specifically anything between 'body' and '/body'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Use regular expressions to extract the documents within the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found  9 documents named  ['[Etext #1]', '[Etext #2]', '[Etext #3]', '[Etext #4]', '[Etext #5]', '[Etext #6]', '[Etext #7]', '[Etext #8]', '[Etext #9]']\n"
     ]
    }
   ],
   "source": [
    "# lets see what we have in the body of the html source\n",
    "# look for text that starts with \"[Etext #]\"\n",
    "\n",
    "data_check = re.findall(r\"\\[Etext #\\d+\\]\", body.text)\n",
    "print('We found ', len(data_check), 'documents named ', data_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Your regex here to capture the documents\n",
    "doc_extractor = r\"(?<=\\[Etext #\\d])([^\\f]+?)(?=\\[Etext #\\d]|\\*\\*\\*End of)\" \n",
    "\n",
    "# Explain this line of code in the cell below.\n",
    "# __Note:__ You will need to use the `re.MULTILINE` flag to ensure that the\n",
    "# regular expression matches across multiple lines.\n",
    "found_documents: list = re.findall(doc_extractor, body.text, flags=re.MULTILINE)\n",
    "    \n",
    "\n",
    "assert len(found_documents) == 9, \"Please check your regex. You should have found a total 9 documents.\"\n",
    "\n",
    "## if you are having trouble with the regex remeber that you can use regex101.com to test and debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(found_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain: `documents = re.findall(doc_extractor, body.text, re.MULTILINE)`\n",
    "\n",
    "This statement its looking for text that start with '[Etext #' and then ends with either 'Etext # ]' or '***End of'. \n",
    "The regular expression has a couple of interesting aspects. One, it's made up of 3 different matching groups. Two, it is matching on the 1st group and the 3rd group but is not selecting them. Third, the multiline flag was needed because the groups could span a single line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Explore the contents of the Documents\n",
    "\n",
    "In the matched documents, you will find a heading appended to the text by project Gutenberg. For the purposes of this assignment, I provided a cleaner function to extract the Gutenberg headings from the text for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gutenberg(text: str) -> str:\n",
    "    \"\"\"Clean the text of a Gutenberg document.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text of a Gutenberg document.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The cleaned text of the document.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\[Etext #\\d+\\]\", \"\", text)\n",
    "    text = re.sub(r\"(\\r\\n)+\", \" \", text)\n",
    "    text = re.sub(r\"^ ?The Project Gutenberg.*?Independence\\*\\*\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?\\*\\*\\*\\*The Project Gutenberg Etext of The U. S. Bill of Rights\\*\\*\\*\\*\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?November.*?EST\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?\\*\\*The Project.*?, USA\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?\\*\\*\\*\\*\\*The Project.*?corrections\\. \\*\\*\\*\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?The Project.*?1775\\.\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?Officially.*?calendar\\]\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?\\*\\*The Project.*?, 1865\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^ ?The Project.*?, 1861\", \"\", text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up corpus\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i, doc in enumerate(found_documents):\n",
    "    cleaned_doc = clean_gutenberg(doc)\n",
    "    corpus.append(cleaned_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc ID 0 is 8113 characters in length\n",
      "doc ID 1 is 2851 characters in length\n",
      "doc ID 2 is 7594 characters in length\n",
      "doc ID 3 is 1514 characters in length\n",
      "doc ID 4 is 26730 characters in length\n",
      "doc ID 5 is 6615 characters in length\n",
      "doc ID 6 is 2027 characters in length\n",
      "doc ID 7 is 3975 characters in length\n",
      "doc ID 8 is 21111 characters in length\n"
     ]
    }
   ],
   "source": [
    "# Well what's the corpus look like\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    print('doc ID',i, 'is', len(corpus[i]), 'characters in length')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the above corpus of documents using TF-IDF\n",
    "\n",
    "In the follow steps, I would like for you to accomplish the follow preprocessing steps. \n",
    "\n",
    "1. Tokenize the documents\n",
    "2. Lemmatize the tokens\n",
    "3. Remove stop words\n",
    "4. Remove punctuation\n",
    "5. Apply TF-IDF to the corpus\n",
    "    * You can write a TF-IDF model from sratch or use the `sklearn` library\n",
    "\n",
    "_tip: see lecture notebooks 4, 5, and 6 for examples of how to work with pandas_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert to lower case and remove punctuation\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].lower()\n",
    "    corpus[i] = re.sub('[^a-zA-Z0-9 ]','',corpus[i])\n",
    "    \n",
    "# lets save the text from the corpus at this point before we tokenize it\n",
    "\n",
    "text = []\n",
    "text = corpus.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the corpus\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = nltk.word_tokenize(corpus[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   docID   9 non-null      int64 \n",
      " 1   text    9 non-null      object\n",
      " 2   tokens  9 non-null      object\n",
      " 3   lemmas  9 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 416.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the declaration of independence of the united ...</td>\n",
       "      <td>[the, declaration, of, independence, of, the, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the united states bill of rights the ten origi...</td>\n",
       "      <td>[the, united, states, bill, of, rights, the, t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>we observe today not a victory of party but a ...</td>\n",
       "      <td>[we, observe, today, not, a, victory, of, part...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>four score and seven years ago our fathers bro...</td>\n",
       "      <td>[four, score, and, seven, years, ago, our, fat...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the constitution of the united states of ameri...</td>\n",
       "      <td>[the, constitution, of, the, united, states, o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>no man thinks more highly than i do of the pat...</td>\n",
       "      <td>[no, man, thinks, more, highly, than, i, do, o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>in the name of god amen  we whose names are un...</td>\n",
       "      <td>[in, the, name, of, god, amen, we, whose, name...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>fellow countrymen  at this second appearing to...</td>\n",
       "      <td>[fellow, countrymen, at, this, second, appeari...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>fellow citizens of the united states  in compl...</td>\n",
       "      <td>[fellow, citizens, of, the, united, states, in...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID                                               text  \\\n",
       "0      0  the declaration of independence of the united ...   \n",
       "1      1  the united states bill of rights the ten origi...   \n",
       "2      2  we observe today not a victory of party but a ...   \n",
       "3      3  four score and seven years ago our fathers bro...   \n",
       "4      4  the constitution of the united states of ameri...   \n",
       "5      5  no man thinks more highly than i do of the pat...   \n",
       "6      6  in the name of god amen  we whose names are un...   \n",
       "7      7  fellow countrymen  at this second appearing to...   \n",
       "8      8  fellow citizens of the united states  in compl...   \n",
       "\n",
       "                                              tokens lemmas  \n",
       "0  [the, declaration, of, independence, of, the, ...         \n",
       "1  [the, united, states, bill, of, rights, the, t...         \n",
       "2  [we, observe, today, not, a, victory, of, part...         \n",
       "3  [four, score, and, seven, years, ago, our, fat...         \n",
       "4  [the, constitution, of, the, united, states, o...         \n",
       "5  [no, man, thinks, more, highly, than, i, do, o...         \n",
       "6  [in, the, name, of, god, amen, we, whose, name...         \n",
       "7  [fellow, countrymen, at, this, second, appeari...         \n",
       "8  [fellow, citizens, of, the, united, states, in...         "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe just because\n",
    "import pandas as pd\n",
    "corpus_df = pd.DataFrame({\"docID\": range(len(corpus)), \"text\": text, \"tokens\": corpus})\n",
    "corpus_df.insert(3,'lemmas', ' ', True)\n",
    "\n",
    "corpus_df.info()\n",
    "\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corpus_df.index:\n",
    "    tokens = corpus_df['tokens'][i]\n",
    "    w = []\n",
    "    for token in tokens:\n",
    "        lemmetized_word = wordnet_lemmatizer.lemmatize(token)\n",
    "        w.append(lemmetized_word)\n",
    "    corpus_df['lemmas'][i] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words\n",
    "\n",
    "You can use the `nltk` library to remove stop words. You can also use the `SpaCy` library to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# index thru each document in the corpus\n",
    "for i in corpus_df.index:\n",
    "    # take the lemmas for this document\n",
    "    unfiltered_lemmas = corpus_df['lemmas'][i]\n",
    "    filtered_tokens = []\n",
    "    # index thru each lemma in the document\n",
    "    for w in unfiltered_lemmas:\n",
    "        if w not in stop_words:\n",
    "            filtered_tokens.append(w)\n",
    "    # place the filtered lemmas into the token column\n",
    "    corpus_df['tokens'][i] = filtered_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point the the tokens column in the corpus dataframe in should contain text that is in lower case, has had the punctuation removed, has been tokenized, converted to lemmas, and finally the stop words removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already removed punctuation in the tokenization step above seemed to make more sense to do it there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the documents and corpus using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After this point a lot of the code was copied from lecture notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>term</th>\n",
       "      <th>term_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>abdicated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>abolish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>abolishing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>absolute</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>8</td>\n",
       "      <td>would</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>8</td>\n",
       "      <td>written</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>8</td>\n",
       "      <td>wrong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>8</td>\n",
       "      <td>year</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>8</td>\n",
       "      <td>yet</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3585 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      docID        term  term_freq\n",
       "0         0        1972          1\n",
       "1         0   abdicated          1\n",
       "2         0     abolish          1\n",
       "3         0  abolishing          3\n",
       "4         0    absolute          3\n",
       "...     ...         ...        ...\n",
       "3580      8       would         10\n",
       "3581      8     written          4\n",
       "3582      8       wrong          1\n",
       "3583      8        year          4\n",
       "3584      8         yet          3\n",
       "\n",
       "[3585 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of this code was copied from the Lecture_06_2023_02_14 notebook\n",
    "\n",
    "\n",
    "# Unwind the data on the tokens\n",
    "corpus_tokens = (corpus_df\n",
    "                  .explode('tokens'))\n",
    "\n",
    "# First calculate the term frequency for each document\n",
    "# create a word frequency dataframe\n",
    "term_freq = (corpus_tokens\n",
    "                  .groupby(by=['docID', 'tokens'])\n",
    "                  .agg({'tokens': 'count'})\n",
    "                  .rename(columns={'tokens': 'term_freq'})\n",
    "                  .reset_index()\n",
    "                  .rename(columns={'tokens': 'term'})\n",
    "                 )\n",
    "term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>term</th>\n",
       "      <th>term_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>4</td>\n",
       "      <td>shall</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>4</td>\n",
       "      <td>state</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>4</td>\n",
       "      <td>united</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>4</td>\n",
       "      <td>law</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>4</td>\n",
       "      <td>may</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>4</td>\n",
       "      <td>president</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>4</td>\n",
       "      <td>congress</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>4</td>\n",
       "      <td>house</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>8</td>\n",
       "      <td>state</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>8</td>\n",
       "      <td>constitution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      docID          term  term_freq\n",
       "1825      4         shall        191\n",
       "1843      4         state        128\n",
       "1907      4        united         55\n",
       "1579      4           law         34\n",
       "1610      4           may         33\n",
       "1708      4     president         32\n",
       "1310      4      congress         29\n",
       "1518      4         house         28\n",
       "3470      8         state         26\n",
       "2882      8  constitution         23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's sort by freq and see the top 10\n",
    "sorted_term_freq_df = term_freq.sort_values(by='term_freq',ascending = False)\n",
    "sorted_term_freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>document_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1774</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>yea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>year</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>yet</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>york</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>young</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       term  document_freq\n",
       "0         1            1.0\n",
       "1        10            1.0\n",
       "2        15            1.0\n",
       "3      1620            1.0\n",
       "4      1774            1.0\n",
       "...     ...            ...\n",
       "2365    yea            1.0\n",
       "2366   year            6.0\n",
       "2367    yet            3.0\n",
       "2368   york            1.0\n",
       "2369  young            1.0\n",
       "\n",
       "[2370 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document frequency\n",
    "\n",
    "document_freq = (term_freq\n",
    "                 .groupby(['docID', 'term'])\n",
    "                 .size()\n",
    "                 .unstack()\n",
    "                 .sum()\n",
    "                 .reset_index()\n",
    "                 .rename(columns={0: 'document_freq'})\n",
    ")\n",
    "document_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>document_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>shall</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>war</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>time</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>december</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>subject</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>government</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>people</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>nation</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>one</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>place</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term  document_freq\n",
       "1950       shall            9.0\n",
       "2294         war            8.0\n",
       "2158        time            8.0\n",
       "558     december            8.0\n",
       "2052     subject            7.0\n",
       "1003  government            7.0\n",
       "1554      people            7.0\n",
       "1419      nation            7.0\n",
       "1491         one            7.0\n",
       "1582       place            7.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's sort by freq and see the top 10\n",
    "sorted_document_freq_df = document_freq.sort_values(by='document_freq',ascending = False)\n",
    "sorted_document_freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tfidf vectorizer with stopwords\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the declaration of independence of the united ...</td>\n",
       "      <td>[declaration, independence, united, state, ame...</td>\n",
       "      <td>[the, declaration, of, independence, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the united states bill of rights the ten origi...</td>\n",
       "      <td>[united, state, bill, right, ten, original, am...</td>\n",
       "      <td>[the, united, state, bill, of, right, the, ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>we observe today not a victory of party but a ...</td>\n",
       "      <td>[observe, today, victory, party, celebration, ...</td>\n",
       "      <td>[we, observe, today, not, a, victory, of, part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>four score and seven years ago our fathers bro...</td>\n",
       "      <td>[four, score, seven, year, ago, father, brough...</td>\n",
       "      <td>[four, score, and, seven, year, ago, our, fath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the constitution of the united states of ameri...</td>\n",
       "      <td>[constitution, united, state, america, 1787, p...</td>\n",
       "      <td>[the, constitution, of, the, united, state, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>no man thinks more highly than i do of the pat...</td>\n",
       "      <td>[man, think, highly, patriotism, well, ability...</td>\n",
       "      <td>[no, man, think, more, highly, than, i, do, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>in the name of god amen  we whose names are un...</td>\n",
       "      <td>[name, god, amen, whose, name, underwritten, l...</td>\n",
       "      <td>[in, the, name, of, god, amen, we, whose, name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>fellow countrymen  at this second appearing to...</td>\n",
       "      <td>[fellow, countryman, second, appearing, take, ...</td>\n",
       "      <td>[fellow, countryman, at, this, second, appeari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>fellow citizens of the united states  in compl...</td>\n",
       "      <td>[fellow, citizen, united, state, compliance, c...</td>\n",
       "      <td>[fellow, citizen, of, the, united, state, in, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID                                               text  \\\n",
       "0      0  the declaration of independence of the united ...   \n",
       "1      1  the united states bill of rights the ten origi...   \n",
       "2      2  we observe today not a victory of party but a ...   \n",
       "3      3  four score and seven years ago our fathers bro...   \n",
       "4      4  the constitution of the united states of ameri...   \n",
       "5      5  no man thinks more highly than i do of the pat...   \n",
       "6      6  in the name of god amen  we whose names are un...   \n",
       "7      7  fellow countrymen  at this second appearing to...   \n",
       "8      8  fellow citizens of the united states  in compl...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [declaration, independence, united, state, ame...   \n",
       "1  [united, state, bill, right, ten, original, am...   \n",
       "2  [observe, today, victory, party, celebration, ...   \n",
       "3  [four, score, seven, year, ago, father, brough...   \n",
       "4  [constitution, united, state, america, 1787, p...   \n",
       "5  [man, think, highly, patriotism, well, ability...   \n",
       "6  [name, god, amen, whose, name, underwritten, l...   \n",
       "7  [fellow, countryman, second, appearing, take, ...   \n",
       "8  [fellow, citizen, united, state, compliance, c...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [the, declaration, of, independence, of, the, ...  \n",
       "1  [the, united, state, bill, of, right, the, ten...  \n",
       "2  [we, observe, today, not, a, victory, of, part...  \n",
       "3  [four, score, and, seven, year, ago, our, fath...  \n",
       "4  [the, constitution, of, the, united, state, of...  \n",
       "5  [no, man, think, more, highly, than, i, do, of...  \n",
       "6  [in, the, name, of, god, amen, we, whose, name...  \n",
       "7  [fellow, countryman, at, this, second, appeari...  \n",
       "8  [fellow, citizen, of, the, united, state, in, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on our model\n",
    "\n",
    "vectors = tfidf_vectorizer.fit_transform(corpus_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with terms and tfidf\n",
    "tfidf_df = pd.DataFrame(vectors.toarray(), index=corpus_df.index.values, columns=tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer.get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senate</th>\n",
       "      <th>house</th>\n",
       "      <th>congress</th>\n",
       "      <th>1776</th>\n",
       "      <th>shall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040452</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.406160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.065085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.107720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136429</td>\n",
       "      <td>0.119766</td>\n",
       "      <td>0.151009</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.587413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.150455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.019549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.114372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058690</td>\n",
       "      <td>0.01809</td>\n",
       "      <td>0.117855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     senate     house  congress     1776     shall\n",
       "0  0.000000  0.000000  0.024365  0.00000  0.014390\n",
       "1  0.000000  0.040452  0.080905  0.00000  0.406160\n",
       "2  0.000000  0.022040  0.000000  0.00000  0.065085\n",
       "3  0.000000  0.000000  0.000000  0.00000  0.107720\n",
       "4  0.136429  0.119766  0.151009  0.00000  0.587413\n",
       "5  0.000000  0.092634  0.000000  0.00000  0.150455\n",
       "6  0.000000  0.000000  0.000000  0.00000  0.019549\n",
       "7  0.000000  0.000000  0.000000  0.00000  0.114372\n",
       "8  0.000000  0.000000  0.058690  0.01809  0.117855"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore some selected terms\n",
    "\n",
    "tfidf_df[['senate', 'house', 'congress', '1776', 'shall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a heatmap of higest terms in some of the documents\n",
    "\n",
    "tfidf_df = (tfidf_df\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: 'tf_idf', 'level_0': 'docID', 'level_1': 'term'})\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the documents by their n highest performing terms\n",
    "\n",
    "n = 5\n",
    "top_tfidf = (tfidf_df\n",
    "             .sort_values(by=['docID','tf_idf'], ascending=[True,False])\n",
    "             .groupby(['docID'])\n",
    "             .head(n)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>term</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "      <td>laws</td>\n",
       "      <td>0.219287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>0.176016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>0</td>\n",
       "      <td>states</td>\n",
       "      <td>0.173932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>assent</td>\n",
       "      <td>0.150204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>colonies</td>\n",
       "      <td>0.150204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>1</td>\n",
       "      <td>shall</td>\n",
       "      <td>0.406160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>1</td>\n",
       "      <td>law</td>\n",
       "      <td>0.242714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>1</td>\n",
       "      <td>states</td>\n",
       "      <td>0.216578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>1</td>\n",
       "      <td>jury</td>\n",
       "      <td>0.183134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>1</td>\n",
       "      <td>right</td>\n",
       "      <td>0.162067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>2</td>\n",
       "      <td>let</td>\n",
       "      <td>0.352636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>2</td>\n",
       "      <td>sides</td>\n",
       "      <td>0.229514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>2</td>\n",
       "      <td>pledge</td>\n",
       "      <td>0.200824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>2</td>\n",
       "      <td>world</td>\n",
       "      <td>0.141279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>2</td>\n",
       "      <td>americans</td>\n",
       "      <td>0.135869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>3</td>\n",
       "      <td>dedicated</td>\n",
       "      <td>0.374783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>3</td>\n",
       "      <td>nation</td>\n",
       "      <td>0.303975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>3</td>\n",
       "      <td>dead</td>\n",
       "      <td>0.281088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>3</td>\n",
       "      <td>conceived</td>\n",
       "      <td>0.187392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>3</td>\n",
       "      <td>dedicate</td>\n",
       "      <td>0.187392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11728</th>\n",
       "      <td>4</td>\n",
       "      <td>shall</td>\n",
       "      <td>0.587413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>4</td>\n",
       "      <td>states</td>\n",
       "      <td>0.376366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>4</td>\n",
       "      <td>united</td>\n",
       "      <td>0.255557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11802</th>\n",
       "      <td>4</td>\n",
       "      <td>state</td>\n",
       "      <td>0.218385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11405</th>\n",
       "      <td>4</td>\n",
       "      <td>president</td>\n",
       "      <td>0.188591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14174</th>\n",
       "      <td>5</td>\n",
       "      <td>sir</td>\n",
       "      <td>0.535369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13139</th>\n",
       "      <td>5</td>\n",
       "      <td>gentlemen</td>\n",
       "      <td>0.249839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13432</th>\n",
       "      <td>5</td>\n",
       "      <td>know</td>\n",
       "      <td>0.150727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14157</th>\n",
       "      <td>5</td>\n",
       "      <td>shall</td>\n",
       "      <td>0.150455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>5</td>\n",
       "      <td>hope</td>\n",
       "      <td>0.138951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16024</th>\n",
       "      <td>6</td>\n",
       "      <td>mr</td>\n",
       "      <td>0.473938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15829</th>\n",
       "      <td>6</td>\n",
       "      <td>john</td>\n",
       "      <td>0.430852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>6</td>\n",
       "      <td>edward</td>\n",
       "      <td>0.255058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16493</th>\n",
       "      <td>6</td>\n",
       "      <td>richard</td>\n",
       "      <td>0.172341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16785</th>\n",
       "      <td>6</td>\n",
       "      <td>thomas</td>\n",
       "      <td>0.172341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361</th>\n",
       "      <td>7</td>\n",
       "      <td>war</td>\n",
       "      <td>0.303413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19409</th>\n",
       "      <td>7</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.179068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>7</td>\n",
       "      <td>union</td>\n",
       "      <td>0.175336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18012</th>\n",
       "      <td>7</td>\n",
       "      <td>god</td>\n",
       "      <td>0.155165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>7</td>\n",
       "      <td>let</td>\n",
       "      <td>0.154919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19906</th>\n",
       "      <td>8</td>\n",
       "      <td>constitution</td>\n",
       "      <td>0.269974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21727</th>\n",
       "      <td>8</td>\n",
       "      <td>union</td>\n",
       "      <td>0.265699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21522</th>\n",
       "      <td>8</td>\n",
       "      <td>states</td>\n",
       "      <td>0.188532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>8</td>\n",
       "      <td>people</td>\n",
       "      <td>0.169592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20451</th>\n",
       "      <td>8</td>\n",
       "      <td>government</td>\n",
       "      <td>0.169296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       docID          term    tf_idf\n",
       "1308       0          laws  0.219287\n",
       "1597       0        people  0.176016\n",
       "2090       0        states  0.173932\n",
       "191        0        assent  0.150204\n",
       "402        0      colonies  0.150204\n",
       "4441       1         shall  0.406160\n",
       "3732       1           law  0.242714\n",
       "4519       1        states  0.216578\n",
       "3705       1          jury  0.183134\n",
       "4352       1         right  0.162067\n",
       "6179       2           let  0.352636\n",
       "6878       2         sides  0.229514\n",
       "6495       2        pledge  0.200824\n",
       "7270       2         world  0.141279\n",
       "4981       2     americans  0.135869\n",
       "7869       3     dedicated  0.374783\n",
       "8745       3        nation  0.303975\n",
       "7849       3          dead  0.281088\n",
       "7719       3     conceived  0.187392\n",
       "7868       3      dedicate  0.187392\n",
       "11728      4         shall  0.587413\n",
       "11806      4        states  0.376366\n",
       "12013      4        united  0.255557\n",
       "11802      4         state  0.218385\n",
       "11405      4     president  0.188591\n",
       "14174      5           sir  0.535369\n",
       "13139      5     gentlemen  0.249839\n",
       "13432      5          know  0.150727\n",
       "14157      5         shall  0.150455\n",
       "13243      5          hope  0.138951\n",
       "16024      6            mr  0.473938\n",
       "15829      6          john  0.430852\n",
       "15297      6        edward  0.255058\n",
       "16493      6       richard  0.172341\n",
       "16785      6        thomas  0.172341\n",
       "19361      7           war  0.303413\n",
       "19409      7           woe  0.179068\n",
       "19298      7         union  0.175336\n",
       "18012      7           god  0.155165\n",
       "18324      7           let  0.154919\n",
       "19906      8  constitution  0.269974\n",
       "21727      8         union  0.265699\n",
       "21522      8        states  0.188532\n",
       "21029      8        people  0.169592\n",
       "20451      8    government  0.169296"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-28ed9ba5181f47cba67e0b50694d6f7b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-28ed9ba5181f47cba67e0b50694d6f7b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-28ed9ba5181f47cba67e0b50694d6f7b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"tf_idf\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"rank\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"docID\", \"type\": \"nominal\"}}, \"title\": \"Heatmap of TF_IDF for Terms\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"field\": \"\", \"as\": \"rank\"}], \"groupby\": [\"docID\"], \"sort\": [{\"field\": \"tf_idf\", \"order\": \"descending\"}]}]}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"value\": \"white\", \"test\": \"(datum.tfidf >= 0.23)\"}, \"value\": \"black\"}, \"text\": {\"field\": \"term\", \"type\": \"nominal\"}, \"x\": {\"field\": \"rank\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"docID\", \"type\": \"nominal\"}}, \"title\": \"Heatmap of TF_IDF for Terms\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"field\": \"\", \"as\": \"rank\"}], \"groupby\": [\"docID\"], \"sort\": [{\"field\": \"tf_idf\", \"order\": \"descending\"}]}]}], \"data\": {\"name\": \"data-9cfacdc246f94ce0936d78aaabab8255\"}, \"height\": 500, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9cfacdc246f94ce0936d78aaabab8255\": [{\"docID\": 0, \"term\": \"laws\", \"tf_idf\": 0.21937320096811344}, {\"docID\": 0, \"term\": \"people\", \"tf_idf\": 0.17609881749223766}, {\"docID\": 0, \"term\": \"states\", \"tf_idf\": 0.17398129800243398}, {\"docID\": 0, \"term\": \"assent\", \"tf_idf\": 0.15023876046457804}, {\"docID\": 0, \"term\": \"colonies\", \"tf_idf\": 0.1502115760037183}, {\"docID\": 1, \"term\": \"shall\", \"tf_idf\": 0.406223461346862}, {\"docID\": 1, \"term\": \"law\", \"tf_idf\": 0.24278601565731503}, {\"docID\": 1, \"term\": \"states\", \"tf_idf\": 0.21665291794800304}, {\"docID\": 1, \"term\": \"jury\", \"tf_idf\": 0.18316213163248465}, {\"docID\": 1, \"term\": \"right\", \"tf_idf\": 0.16209238931867753}, {\"docID\": 2, \"term\": \"let\", \"tf_idf\": 0.35271350900762005}, {\"docID\": 2, \"term\": \"sides\", \"tf_idf\": 0.22953950212305152}, {\"docID\": 2, \"term\": \"pledge\", \"tf_idf\": 0.20089988662638478}, {\"docID\": 2, \"term\": \"world\", \"tf_idf\": 0.14129838056028307}, {\"docID\": 2, \"term\": \"americans\", \"tf_idf\": 0.1359407021517921}, {\"docID\": 3, \"term\": \"dedicated\", \"tf_idf\": 0.3748277097987335}, {\"docID\": 3, \"term\": \"nation\", \"tf_idf\": 0.30402824799668965}, {\"docID\": 3, \"term\": \"dead\", \"tf_idf\": 0.28118444391263264}, {\"docID\": 3, \"term\": \"conceived\", \"tf_idf\": 0.18740482089819405}, {\"docID\": 3, \"term\": \"dedicate\", \"tf_idf\": 0.18744163614665468}, {\"docID\": 4, \"term\": \"shall\", \"tf_idf\": 0.5874184177193559}, {\"docID\": 4, \"term\": \"states\", \"tf_idf\": 0.37637299064447544}, {\"docID\": 4, \"term\": \"united\", \"tf_idf\": 0.2555839742932167}, {\"docID\": 4, \"term\": \"state\", \"tf_idf\": 0.2184406727253488}, {\"docID\": 4, \"term\": \"president\", \"tf_idf\": 0.1886434985210538}, {\"docID\": 5, \"term\": \"sir\", \"tf_idf\": 0.5354398377685079}, {\"docID\": 5, \"term\": \"gentlemen\", \"tf_idf\": 0.24990845413857743}, {\"docID\": 5, \"term\": \"know\", \"tf_idf\": 0.1508210001528619}, {\"docID\": 5, \"term\": \"shall\", \"tf_idf\": 0.15048293061807824}, {\"docID\": 5, \"term\": \"hope\", \"tf_idf\": 0.1389817282350932}, {\"docID\": 6, \"term\": \"mr\", \"tf_idf\": 0.4739992741977551}, {\"docID\": 6, \"term\": \"john\", \"tf_idf\": 0.4309422484580019}, {\"docID\": 6, \"term\": \"edward\", \"tf_idf\": 0.25515749926251013}, {\"docID\": 6, \"term\": \"richard\", \"tf_idf\": 0.17235168861443753}, {\"docID\": 6, \"term\": \"thomas\", \"tf_idf\": 0.17238862410773845}, {\"docID\": 7, \"term\": \"war\", \"tf_idf\": 0.3035004634380112}, {\"docID\": 7, \"term\": \"woe\", \"tf_idf\": 0.17914508735775744}, {\"docID\": 7, \"term\": \"union\", \"tf_idf\": 0.17534660811573455}, {\"docID\": 7, \"term\": \"god\", \"tf_idf\": 0.15525756909810487}, {\"docID\": 7, \"term\": \"let\", \"tf_idf\": 0.1549324831282265}, {\"docID\": 8, \"term\": \"constitution\", \"tf_idf\": 0.2700268190458087}, {\"docID\": 8, \"term\": \"union\", \"tf_idf\": 0.2657852989732103}, {\"docID\": 8, \"term\": \"states\", \"tf_idf\": 0.188557731515655}, {\"docID\": 8, \"term\": \"people\", \"tf_idf\": 0.16969026228111178}, {\"docID\": 8, \"term\": \"government\", \"tf_idf\": 0.1693024682452307}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this looks way more complicated than seaborn heatmaps\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "# adding a little randomness to break ties in term ranking\n",
    "top_tfidf_rand = top_tfidf.copy()\n",
    "top_tfidf_rand['tf_idf'] = top_tfidf_rand['tf_idf'] + np.random.rand(top_tfidf.shape[0])*0.0001\n",
    "\n",
    "\n",
    "base = alt.Chart(top_tfidf_rand, title=\"Heatmap of TF_IDF for Terms\").encode(\n",
    "    x = 'rank:O',\n",
    "    y = 'docID:N'\n",
    ").transform_window(\n",
    "    rank = \"rank()\",\n",
    "    sort = [alt.SortField(\"tf_idf\", order=\"descending\")],\n",
    "    groupby = [\"docID\"],\n",
    ")\n",
    "\n",
    "# heatmap specification\n",
    "heatmap = base.mark_rect().encode(color = 'tf_idf:Q')\n",
    "\n",
    "# text labels, white for darker heatmap colors\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text = 'term:N',\n",
    "    color = alt.condition(alt.datum.tfidf >= 0.23, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# display the three superimposed visualizations\n",
    "(heatmap + text).properties(width=500,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "Please submit your assignment as a Jupyter Notebook or R Markdown file. You can submit your assignment as a link to a Google Colab notebook or a link to a GitHub repository. If you are submitting a link to a GitHub repository, please make sure that your repository is public. If you email the notebook to me, please zip the file before sending it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA 340-03 NLP - WebScraping Assignment - Mark J. Serena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d99a3f87c484a74ba405ca572f7f1b4059e93a8c4d7f8027bf5ae12e7919d9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
